{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Named Entity Recognition (NER) Notebook\n",
        "Clean, commented implementation for training a BiLSTM NER model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Load dataset\n",
        "data = pd.read_csv('ner_dataset.csv', encoding='unicode_escape')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import chain\n",
        "\n",
        "def get_dict_map(data, token_or_tag):\n",
        "    \"\"\"Creates token\u2194index mappings\"\"\"\n",
        "    if token_or_tag == 'token':\n",
        "        vocab = list(set(data['Word'].to_list()))\n",
        "    else:\n",
        "        vocab = list(set(data['Tag'].to_list()))\n",
        "\n",
        "    idx2tok = {idx: tok for idx, tok in enumerate(vocab)}\n",
        "    tok2idx = {tok: idx for idx, tok in idx2tok.items()}\n",
        "    return tok2idx, idx2tok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def get_pad_train_test_val(data_group, data):\n",
        "    \"\"\"Pads sequences and splits dataset\"\"\"\n",
        "\n",
        "    n_token = len(set(data['Word'].to_list()))\n",
        "    n_tag = len(set(data['Tag'].to_list()))\n",
        "\n",
        "    tokens = pad_sequences(data_group['Word_idx'], maxlen=max_len, padding='post')\n",
        "    tags = pad_sequences(data_group['Tag_idx'], maxlen=max_len, padding='post')\n",
        "\n",
        "    tags = [to_categorical(i, num_classes=n_tag) for i in tags]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(tokens, tags, test_size=0.1)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras import Sequential, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Bidirectional\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(1)\n",
        "tensorflow.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "input_dim = len(set(data['Word'].to_list())) + 1\n",
        "output_dim = 64\n",
        "input_length = 50  # adjust based on dataset\n",
        "n_tags = len(set(data['Tag'].to_list()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_bilstm_lstm_model():\n",
        "    \"\"\"Builds BiLSTM sequence labeling model\"\"\"\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(input_length,)))\n",
        "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(output_dim, return_sequences=True, dropout=0.2)))\n",
        "    model.add(LSTM(output_dim, return_sequences=True, dropout=0.5))\n",
        "\n",
        "    model.add(TimeDistributed(Dense(n_tags, activation='softmax')))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(X, y, model):\n",
        "    \"\"\"Trains model and records loss\"\"\"\n",
        "    losses = []\n",
        "    for i in range(5):\n",
        "        history = model.fit(X, y, batch_size=256, epochs=1, validation_split=0.2)\n",
        "        losses.append(history.history['loss'][0])\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## spaCy Visualization Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "doc = nlp(\"Apple hired John in London\")\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}